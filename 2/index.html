<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>CS180 Project 2: Image Blending and Pyramid Representations</title>
  <link
    href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@400;700&family=Open+Sans:ital,wght@0,400;0,700;1,600&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="style.css">
 <style>
  body {
    font-family: 'Open Sans', sans-serif;
    max-width: 1000px;
    margin: auto;
    padding: 20px;
  }
  h2 {
    margin-top: 40px;
    text-align: center;
  }
  .gallery {
    display: grid;
    grid-template-columns: repeat(3, 1fr); /* three per row */
    gap: 20px;
    margin-top: 20px;
  }
  figure {
    text-align: center;
    margin: 0;
    display: flex;
    flex-direction: column;
    align-items: center; /* centers the image horizontally */
  }
  figcaption {
    font-size: 14px;
    color: #555;
    margin-top: 6px;
  }
  img {
    width: 300px;
    height: auto;
    display: block;
  }
  .large-img {
  width: 1100px; 
}
  @media (max-width: 600px) {
    .gallery {
      grid-template-columns: 1fr;
    }
    img {
      width: 100%;
      height: auto;
    }
  }
</style>

</head>
<body>
  <h1>CS180 Project 2: Image Blending and Pyramid Representations</h1>
  <b>By Justin Zhou</b>

  <h2>1.1 Convolutions from Scratch</h2>
  <p>
For this part of the project, I implemented a 2D convolution with one being four for loop and the other two. I applied them to a grayscale selfie using a 9Ã—9 box filter and Dx/Dy operators.  </p>
  <div class="gallery">
    <figure>
      <img src="media/me.jpg" alt="Me normal">
      <figcaption>Me</figcaption>
    </figure>
    <figure>
      <img src="media/me_x.jpg" alt="Cat image">
      <figcaption>Me (D_x)</figcaption>
    </figure>
    <figure>
      <img src="media/me_y.jpg" alt="Hybrid image">
      <figcaption>Me(D_y)</figcaption>
    </figure>
    <figure>
      <img src="media/me_box.jpg" alt="Hybrid image">
      <figcaption>Me (Box filter)</figcaption>
    </figure>
  </div>
  <h3>Code Snippets</h3>
        <pre><code>def conv2d_4loops(img, kernel):
    H, W = img.shape
    h, w = kernel.shape
    padH, padW = h // 2, w // 2
    
    padding = np.pad(img, ((padH, padH), (padW, padW)), mode='constant')
    out = np.zeros_like(img)

    for i in range(H):
        for j in range(W):
            temp = 0
            for m in range(h):
                for n in range(w):
                    temp += kernel[m, n] * padding[i + m, j + n]
            out[i, j] = temp
    return out

def conv2d_2loops(img, kernel):
    H, W = img.shape
    h, w = kernel.shape
    pad_h, pad_w = h // 2, w // 2
    padding = np.pad(img, ((pad_h, pad_h), (pad_w, pad_w)))
    out = np.zeros_like(img)
    for i in range(H):
        for j in range(W):
            region = padding[i:i + h, j:j + w]
            out[i, j] = np.sum(region * kernel)
    return out
</code></pre>
<p>Both iterative convolution functions have zero-padding to preserve dimensions. The four for loop version is significantly than the two for loop one, and both are much slower than <code>scipy.signal.convolve2d</code>, though they produce identical results which is hard to see because of the image quality.</p>

  <h2>1.2 Finite Difference Operator</h2>
  <p>
    For this section, I applied Dx and Dy to the provided cameraman image to compute partial derivatives, combined them to obtain the gradient magnitude, and binarized it with a chosen threshold to produce a clean edge map.
  </p>
  <div class="gallery">
    <figure>
      <img src="media/camerman.png" alt="dx result">
      <figcaption>Original</figcaption>
    </figure>
    <figure>
      <img src="media/camera_x.jpg" alt="dy result">
      <figcaption>Partial Derivative (dy)</figcaption>
    </figure>
    <figure>
      <img src="media/camera_y.jpg" alt="Gradient magnitude">
      <figcaption>Partial Derivative (dy)</figcaption>
    </figure>
    <figure>
      <img src="media/camera_mag.jpg" alt="dy result">
      <figcaption>Gradient Magnitude</figcaption>
    </figure>
    <figure>
      <img src="media/camera_mag.jpg" alt="Gradient magnitude">
      <figcaption>Edge Map</figcaption>
    </figure>
  </div>

  <h2>1.3 Derivative of Gaussian (DoG) Filter</h2>
  <p>
    To improve the results from the previous section, I was tasked to reduced noise by smoothing with a Gaussian filter before applying Dx and Dy and then verifying the convolution properties by convolving Gaussian with the derivative filters.
  </p>
  <div class="gallery">
    <figure>
      <img src="media/part13.jpg" alt="DoG dx" class="large-img">
      <figcaption>DoG</figcaption>
    </figure>
  </div>
  <p>Compared to the finite difference operator, the DoG filter produced a cleaner edge map by reducing background noise while preserving main edges.</p>

  <h2>2.1 Image Sharpening</h2>
  <p>
In this section, image sharpening was performed using the unsharp mask filter. 
This process enhances high-frequency details by subtracting a Gaussian-blurred version from the original image and adding the difference back. 
Comparing the results, I noted that the filter failed to recover image quality after being put through the transformation sequence, 
showing that this process does not restore the information lost from blurring.  </p>
  <div class="gallery">
    <figure>
      <img src="media/taj.jpg" alt="Original Taj Mahal">
      <figcaption>Original Taj Mahal</figcaption>
    </figure>
    <figure>
      <img src="media/taj_blurred.png" alt="Sharpened Taj Mahal">
      <figcaption>Blurred Taj Mahal</figcaption>
    </figure>
    <figure>
      <img src="media/taj_sharp.png" alt="Sharpened Taj Mahal">
      <figcaption>Sharpened Taj Mahal</figcaption>
    </figure>
    <figure>
      <img src="media/blurrykid.jpg" alt="Original Taj Mahal">
      <figcaption>Kid</figcaption>
    </figure>
    <figure>
      <img src="media/kid_sharp.jpg" alt="Sharpened Taj Mahal">
      <figcaption>Sharpened Kid</figcaption>
    </figure>
  </div>
  <p>With the original image, being quite blurry. I can see some improvements from the original image or perhaps it is all placebo.</p>
  <h2>2.2 Hybrid Images</h2>
  <p>
    Here are some hybrid images, I constructed by combining low and high frequencies.
  </p>
  <div class="gallery">
    <figure>
      <img src="media/elon.jpg" alt="Apple">
      <figcaption>Elon (a controversial figure)</figcaption>
    </figure>
    <figure>
      <img src="media/zuckv2.jpeg" alt="Orange">
      <figcaption>Mark Zuckerberg (another figure...)</figcaption>
    </figure>
    <figure>
      <img src="media/zucklon.jpg" alt="Orapple hybrid">
      <figcaption>Zucklon: Elon and Zuck</figcaption>
    </figure>
    <figure>
      <img src="media/mkt.jpeg" alt="Apple">
      <figcaption>Mike Tyson</figcaption>
    </figure>
    <figure>
      <img src="media/wls.jpeg" alt="Orange">
      <figcaption>Will Smith</figcaption>
    </figure>
    <figure>
      <img src="media/willsmithmiketyson.jpg" alt="Orapple hybrid">
      <figcaption>Will Smith and Mike Tyson, I think this one turned out worse because Will Smith had a different posture compared to Tyson</figcaption>
    </figure>
    <figure>
      <img src="media/zucklonfft.jpg" alt="Orapple hybrid">
      <figcaption>FFT of Elon and Zuck</figcaption>
    </figure>
    <figure>
      <img src="media/wlsmktfft.jpg" alt="Orapple hybrid">
      <figcaption>FFT of Smith and Tyson</figcaption>
      </figure>
  </div>

  <h2>2.3 Gaussian and Laplacian Stacks</h2>
  <div class="gallery">
    <figure>
      <img src="results/gaussian_stack.png" alt="Gaussian stack">
      <figcaption>Gaussian Stack</figcaption>
    </figure>
    <figure>
      <img src="results/laplacian_stack.png" alt="Laplacian stack">
      <figcaption>Laplacian Stack</figcaption>
    </figure>
  </div>

  <h2>2.4 Multiresolution Blending</h2>
  <p>
Here are some Hybrid Images:
  </p>
  <div class="gallery">
    <figure>
      <img src="media/apple.jpeg" alt="Apple">
      <figcaption>Apple (low frequencies)</figcaption>
    </figure>
    <figure>
      <img src="media/orange.jpeg" alt="Orange">
      <figcaption>Orange (high frequencies)</figcaption>
    </figure>
    <figure>
      <img src="media/oraple.png" alt="Orapple hybrid">
      <figcaption>Hybrid: Orapple</figcaption>
    </figure>
    <figure>
      <img src="media/fhrome.png" alt="Apple">
      <figcaption>Firefox and Chrome(didnt turn out well since Firefox isnt a circle)</figcaption>
    </figure>
    <figure>
      <img src="media/mupiter.png" alt="Orange">
      <figcaption>Mars and Jupiter</figcaption>
    </figure>
    <figure>
      <img src="media/ucba.png" alt="Orapple hybrid">
      <figcaption>UCBA: Combination of UCLA and Berkeley</figcaption>
    </figure>
  </div>

  <h2>Reflection</h2>
  <p>
Going in, I thought this project would be similiar to a photoshop workshop. However, this project deepened my understanding of frequency analysis in image processing, including edge detection with filters, noise reduction via Gaussian smoothing, and seamless blending through multiresolution techniques. The hybrid image experiments also highlighted how human perception interprets different frequencies at varying viewing distances, which I found very interesting. </p>
</body>
</html>
